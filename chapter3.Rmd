---
title: 'Statistical Rethinking: A Bayesian Course with Examples in R and Stan'
subtitle: 'Chapter 3: Sampling the Imaginary'
author: "Marwin Carmo"
date: "12/01/2022"
output: 
  html_document:
    theme: flatly
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, include=FALSE}
library(rethinking)
library(ggplot2)
```

## 3.1. Sampling from a grid-approximate posterior

```{r 3.2}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) 
prob_p <- rep( 1 , 1000 ) 
prob_data <- dbinom( 6 , size=9 , prob=p_grid ) 
posterior <- prob_data * prob_p 
posterior <- posterior / sum(posterior)

samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )

plot( samples )
dens( samples )
```

```{r 3.11}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) 
prior <- rep(1,1000) 
likelihood <- dbinom( 3 , size=3 , prob=p_grid ) 
posterior <- likelihood * prior 
posterior <- posterior / sum(posterior) 
samples <- sample( p_grid , size=1e4 , replace=TRUE , prob=posterior )
```


## 3.2. Sampling to summarize

```{r}
mean( samples ) 
median( samples )
```

### Loss Function

```{r loss}
loss <- sapply( p_grid , function(d) sum( posterior*abs( d - p_grid ) ) )
plot(x=p_grid, y=loss, type="l", xlab="decision", ylab="expected proportional loss")
abline(v=p_grid[ which.min(loss) ], col="red", lty=2)
#points(x=p_grid[ which.min(loss) ], col = "red", pch = 19)
```

## 3.3. Sampling to simulate prediction

```{r 3.25}

w <- rbinom( 1e4 , size=9 , prob=samples )
simplehist(w)


```

## 3.5 Practice

```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) 
prior <- rep( 1 , 1000 ) 
likelihood <- dbinom( 6 , size=9 , prob=p_grid ) 
posterior <- likelihood * prior 
posterior <- posterior / sum(posterior)
set.seed(100) 
samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )
```

### 3E1. How much posterior probability lies below p = 0.2?

```{r 3e1}
sum(samples < 0.2)/length(samples)
```

### 3E2. How much posterior probability lies above p = 0.8?

```{r 3e2}
sum(samples > 0.8)/length(samples)
```

### 3E3. How much posterior probability lies between p = 0.2 and p = 0.8?

```{r 3e3}
sum(samples > 0.2 & samples < 0.8)/length(samples)
```

### 3E4. 20% of the posterior probability lies below which value of *p*?

```{r 3e4}
quantile(samples, 0.2)
```

### 3E5. 20% of the posterior probability lies above which value of *p*?

```{r 3e5}
quantile(samples, 0.8)
```

### 3E6. Which values of p contain the narrowest interval equal to 66% of the posterior probability?

To answer that question, we need to calculate the Highest Posterior Density Interval (HDPI)

```{r 3e6}
rethinking::HPDI(samples, 0.66)
```


```{r}
dat <- with(density(samples), data.frame(x, y))
ggplot(data = dat, mapping = aes(x = x, y = y)) +
    geom_line() +
    geom_area(mapping = aes(x = ifelse(x > rethinking::HPDI(samples, 0.66)[[1]] & x < rethinking::HPDI(samples, 0.66)[[2]], x, 0)), fill = "red", alpha = 0.7) +
    scale_y_continuous(limits = c(0, max(dat$y))) +
    theme_bw(12) +
    labs(y = "Density")
```

### 3E7. Which values of p contain 66% of the posterior probability, assuming equal posterior probability both below and above the interval?

Now we need to find the **central** 66% probability

```{r 3e7}
rethinking::PI(samples, .66)

ggplot(data = dat, mapping = aes(x = x, y = y)) +
    geom_line() +
    geom_area(mapping = aes(x = ifelse(x > rethinking::PI(samples, .66)[[1]] & x < rethinking::PI(samples, .66)[[2]], x, 0)), fill = "red", alpha = 0.7) +
    scale_y_continuous(limits = c(0, max(dat$y))) +
    theme_bw(12) +
    labs(y = "Density")
```

### 3M1. Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before.

```{r 3m1}
p_grid <- seq( from=0 , to=1 , length.out=1000 ) 
prior <- rep( 1 , 1000 ) 
likelihood <- dbinom( 8 , size=15 , prob=p_grid ) 
posterior <- likelihood * prior 
posterior <- posterior / sum(posterior)

```

### 3M2. Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for p.

```{r 3m2}
set.seed(100) 
samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )
rethinking::HPDI(samples, 0.9)

dat <- with(density(samples), data.frame(x, y))
ggplot(data = dat, mapping = aes(x = x, y = y)) +
    geom_line() +
    geom_area(mapping = aes(x = ifelse(x > rethinking::HPDI(samples, 0.9)[[1]] & x < rethinking::HPDI(samples, 0.9)[[2]], x, 0)), fill = "red", alpha = 0.7) +
    scale_y_continuous(limits = c(0, max(dat$y))) +
    theme_bw(12) +
    labs(y = "Density")
```
### 3M3. Construct a posterior predictive check for this model and data. This means simulate the distribution of samples, averaging over the posterior uncertainty in p. What is the probability of observing 8 water in 15 tosses?

```{r 3m3}
# simulate predictive observations for each p in samples
w <- rbinom(1e4, size = 15, prob = samples)
sum(w == 8)/length(w)
```

